{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84894,"databundleVersionId":9709193,"sourceType":"competition"},{"sourceId":7949759,"sourceType":"datasetVersion","datasetId":4675026}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-24T04:38:20.817944Z","iopub.execute_input":"2024-10-24T04:38:20.818445Z","iopub.status.idle":"2024-10-24T04:38:22.154627Z","shell.execute_reply.started":"2024-10-24T04:38:20.818397Z","shell.execute_reply":"2024-10-24T04:38:22.152958Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s4e10/sample_submission.csv\n/kaggle/input/playground-series-s4e10/train.csv\n/kaggle/input/playground-series-s4e10/test.csv\n/kaggle/input/loan-approval-prediction/credit_risk_dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"from scipy.stats import norm, skew\nfrom scipy import stats\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\ncolor=sns.color_palette()\nsns.set_style('darkgrid')\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn import svm\n\nimport warnings\nwarnings.filterwarnings('ignore')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T04:38:24.544207Z","iopub.execute_input":"2024-10-24T04:38:24.545066Z","iopub.status.idle":"2024-10-24T04:38:26.792160Z","shell.execute_reply.started":"2024-10-24T04:38:24.545008Z","shell.execute_reply":"2024-10-24T04:38:26.790818Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train=pd.read_csv('../input/playground-series-s4e10/train.csv')\ntest=pd.read_csv('../input/playground-series-s4e10/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"train_size:{}\".format(train.shape))\nprint(\"test_size:{}\".format(test.shape))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original = pd.read_csv('/kaggle/input/loan-approval-prediction/credit_risk_dataset.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original.head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I noticed that loan_int_rate have a strong correlation with loan_grade! So, I used the average value of each loan_grade to fill in loan_int_rate","metadata":{}},{"cell_type":"code","source":"original['loan_int_rate'] = pd.to_numeric(original['loan_int_rate'], errors='coerce')\nmean_rates = original.groupby('loan_grade')['loan_int_rate'].mean()\nfor grade, mean_rate in mean_rates.items():\n    original.loc[(original['loan_grade'] == grade) & (original['loan_int_rate'].isna()), 'loan_int_rate'] = mean_rate\nprint(original)\noriginal.to_csv('filled_credit_risk_dataset.csv', index=False)\n\nnew_original = pd.read_csv('filled_credit_risk_dataset.csv')\nnew_original.head(100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_int_rate = new_original[new_original['loan_int_rate'].isna()]\nprint(missing_int_rate)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nI tried to find the correlation between person_emp_length and person_age","metadata":{}},{"cell_type":"code","source":"sampled_data = original.sample(n=12, random_state=42)\ndata = sampled_data[['person_age', 'person_emp_length']]\nplt.figure(figsize=(10, 6))\nsns.scatterplot(x='person_age', y='person_emp_length', data=data)\nslope, intercept = np.polyfit(data['person_age'], data['person_emp_length'], 1)\nline = slope * data['person_age'] + intercept\nplt.plot(data['person_age'], line, color='red', label='Regression Line')\nplt.text(0.05, 0.95, f'Line: y = {slope:.2f}x + {intercept:.2f}', \n         transform=plt.gca().transAxes, fontsize=12, verticalalignment='top')\n\nplt.title('Relationship between Person Age and Employment Length')\nplt.xlabel('Person Age')\nplt.ylabel('Employment Length (Years)')\nplt.legend()\n\nplt.grid(True)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sampled_data = original.sample(n=1000, random_state=42)\ndata = sampled_data[['person_age', 'person_emp_length']]\nplt.figure(figsize=(10, 6))\nsns.scatterplot(x='person_age', y='person_emp_length', data=data)\n\nplt.title('Relationship between Person Age and Employment Length (Sampled Data)')\nplt.xlabel('Person Age')\nplt.ylabel('Employment Length (Years)')\n\nplt.grid(True)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I did not find the correlation between person_emp_length and person_age. So I just used average value to fill in.","metadata":{}},{"cell_type":"code","source":"new_original['person_emp_length'].fillna(new_original['person_emp_length'].mean(), inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_original.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"obj_cols = (['person_home_ownership', 'loan_intent', 'loan_grade',\n            'cb_person_default_on_file'])\nnum_cols = (['person_age', 'person_income', 'person_emp_length',\n            'loan_amnt', 'loan_int_rate', 'loan_percent_income', \n            'cb_person_cred_hist_length'])\n\nfeatures = obj_cols + num_cols ","metadata":{"execution":{"iopub.status.busy":"2024-10-24T04:39:33.897703Z","iopub.execute_input":"2024-10-24T04:39:33.898148Z","iopub.status.idle":"2024-10-24T04:39:33.904815Z","shell.execute_reply.started":"2024-10-24T04:39:33.898108Z","shell.execute_reply":"2024-10-24T04:39:33.903554Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train['label'] = 0\nnew_original['label'] = 1\ntarget = 'label'\n\nall_cols = features + [target]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[all_cols].shape, new_original[all_cols].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_adversarial_data(train, new_original, cols, N_val=50000):\n    combined_data = pd.concat([train[cols], new_original[cols]], axis=0)\n    adversarial_test = combined_data.sample(N_val, replace=False)\n    adversarial_train = combined_data.drop(adversarial_test.index)\n    return adversarial_train, adversarial_test\n\nadversarial_train, adversarial_test = create_adversarial_data(train, new_original, all_cols)\nadversarial_train.shape, adversarial_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import catboost\nfrom catboost import Pool, CatBoostClassifier\n\ntrain_data = Pool(\n    data=adversarial_train[features],\n    label=adversarial_train[target],\n    cat_features=obj_cols\n)\nholdout_data = Pool(\n    data=adversarial_test[features],\n    label=adversarial_test[target],\n    cat_features=obj_cols\n)\n\ncatboost_params = {\n    'iterations': 100,\n    'eval_metric': 'AUC',\n    'od_type': 'Iter',\n    'od_wait': 50,\n    'random_seed': 50,\n    'verbose': 0\n}\n\nmodel = CatBoostClassifier(**catboost_params)\n_ = model.fit(train_data, eval_set=holdout_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set up ROC Curve plot\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import roc_curve, roc_auc_score, log_loss\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\ndef plot_roc(y_trues, y_preds, labels, x_max=1.0):\n    fig, ax = plt.subplots()\n    for i, (y_true, y_pred) in enumerate(zip(y_trues, y_preds)): \n        fpr, tpr, _ = roc_curve(y_true, y_pred)\n        auc_score = roc_auc_score(y_true, y_pred)\n        ax.plot(fpr, tpr, label=f'{labels[i]}; AUC={auc_score:.3f}', marker='o', markersize=1)\n    \n\n    ax.plot(np.linspace(0, 1, 20), np.linspace(0, 1, 20), linestyle='--', color='grey') \n    ax.legend()\n    ax.grid()\n    ax.set_title('ROC curve')\n    ax.set_xlabel('False Positive Rate')\n    ax.set_xlim([-0.01, x_max])\n    ax.set_ylabel('True Positive Rate')\n    \n# Plot\nplot_roc(\n    y_trues=[holdout_data.get_label()],\n    y_preds=[model.predict_proba(holdout_data)[:,1]],\n    labels=['Baseline']\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\nfrom lightgbm import LGBMClassifier\n\nimport shap\nshap.initjs()\n\n# Define function to plot feature importance\ndef plot_importances(model, holdout_data, features):\n    shap_values = model.get_feature_importance(holdout_data, type='ShapValues')\n    expected_value = shap_values[0,-1]\n    shap_values = shap_values[:,:-1]\n    shap.summary_plot(shap_values, holdout_data, feature_names=features, plot_type='bar')\n    \n# Plot feature importance\nplot_importances(model, holdout_data, features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove 'person_income' and retrain the model\nupdated_params = catboost_params.copy()\nupdated_params['ignored_features'] = ['person_income']\nmodel2 = CatBoostClassifier(**updated_params)\nmodel2.fit(train_data, eval_set=holdout_data, plot=True, verbose=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot updated ROC Curve plot\nplot_roc(\n    y_trues=[holdout_data.get_label()]*2,\n    y_preds=[model.predict_proba(holdout_data)[:, 1], model2.predict_proba(holdout_data)[:, 1]],\n    labels=['Baseline', \"Removing 'person_income'\"] \n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove 'loan_int_rate' and retrain the model\nupdated_params = catboost_params.copy()\nupdated_params['ignored_features'] = ['loan_int_rate']\nmodel2 = CatBoostClassifier(**updated_params)\nmodel2.fit(train_data, eval_set=holdout_data, plot=True, verbose=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot updated ROC Curve plot\nplot_roc(\n    y_trues=[holdout_data.get_label()]*2,\n    y_preds=[model.predict_proba(holdout_data)[:, 1], model2.predict_proba(holdout_data)[:, 1]],\n    labels=['Baseline', \"Removing 'loan_int_rate'\"] \n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"AUC = 0.6 to 0.7, this is not close to 0.5 or 1,so the train data and the original data do not have same distribution. let me remove original data.","metadata":{}},{"cell_type":"code","source":"train=pd.read_csv('../input/playground-series-s4e10/train.csv')\ntest=pd.read_csv('../input/playground-series-s4e10/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-10-24T04:38:48.897361Z","iopub.execute_input":"2024-10-24T04:38:48.898515Z","iopub.status.idle":"2024-10-24T04:38:49.176076Z","shell.execute_reply.started":"2024-10-24T04:38:48.898453Z","shell.execute_reply":"2024-10-24T04:38:49.174783Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def preprocess(df):\n    df['loan_to_income'] = ((df['loan_amnt'] / df['person_income']) - df['loan_percent_income']).astype('string').astype('category')\n    df['age_income_interaction'] = (df['person_age'] * df['person_income']).astype('string').astype('category')\n    df['loan_to_emp_length_ratio'] = (df['loan_amnt'] / df['person_emp_length'].replace({'None': original['person_emp_length'].mean()}).astype('float')).astype('string').astype('category')\n    monthly_income = df['person_income'] / 12\n    df['monthly_debt'] = (df['loan_amnt'] * (1 + df['loan_int_rate'].replace({'None': original['loan_int_rate'].mean()})) / 12)\n    df['dti_ratio'] = (df['monthly_debt'] / monthly_income).astype('string').astype('category')\n    df['monthly_debt'] = df['monthly_debt'].astype('string').astype('category')\n    df['risk_flag'] = (np.where((df['cb_person_default_on_file'] == 'Y') & (df['loan_grade'].isin(['C', 'D', 'E'])), 1, 0))\n    df['risk_flag'] = df['risk_flag'].astype('category')\n    df['person_home_ownership'] = df['person_home_ownership'].astype('category')\n    df['loan_intent'] = df['loan_intent'].astype('category')\n    df['loan_grade'] = df['loan_grade'].astype('category')\n    df['cb_person_default_on_file'] = df['cb_person_default_on_file'].astype('category')\n    df['person_emp_length'] = df['person_emp_length'].astype('string').astype('category')\n    df['loan_int_rate'] = (df['loan_int_rate'] * 100).astype('string').astype('category')\n    df['loan_percent_income'] = (df['loan_percent_income'] * 100).astype('string').astype('category')\n\npreprocess(test)\npreprocess(train)\ny = train.pop('loan_status')","metadata":{"execution":{"iopub.status.busy":"2024-10-22T01:49:35.576292Z","iopub.execute_input":"2024-10-22T01:49:35.576725Z","iopub.status.idle":"2024-10-22T01:49:36.932198Z","shell.execute_reply.started":"2024-10-22T01:49:35.576681Z","shell.execute_reply":"2024-10-22T01:49:36.930674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import optuna\nimport numpy as np\nfrom catboost import CatBoostClassifier, Pool\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom optuna.samplers import TPESampler\n\ndef objective(trial):\n    params = {\n        'loss_function': 'Logloss',\n        'eval_metric': 'AUC',\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n        'iterations': 1000,\n        'depth': trial.suggest_int('depth', 5, 10),\n        'random_strength': 0,\n        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-1, 1.0, log=True),\n        'task_type': 'GPU',\n        'random_seed': 50,\n        'verbose': False\n    }\n    \n    model = CatBoostClassifier(**params)\n    cv = StratifiedKFold(5, shuffle=True, random_state=0)\n    cv_splits = cv.split(train, y)\n    scores = []\n    \n    # Cross-validation loop\n    for train_idx, val_idx in cv_splits:\n        train_train_fold, train_val_fold = train.iloc[train_idx], train.iloc[val_idx]\n        y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n        \n        train_train_pool = Pool(train_train_fold, y_train_fold, cat_features=train.columns.values)\n        train_valid_pool = Pool(train_val_fold, y_val_fold, cat_features=train.columns.values)\n        \n        model.fit(train_pool=train_train_pool, eval_set=train_valid_pool, verbose=False, early_stopping_rounds=200)\n        val_pred = model.predict_proba(train_valid_pool)[:, 1]\n        score = roc_auc_score(y_val_fold, val_pred)\n        scores.append(score)\n    \n    return np.mean(scores)\n\n# Optuna\nsqlite_db = \"sqlite:///catboost.db\"\nstudy_name = \"catboost\"\noptimize = False\n\nif optimize:\n    study = optuna.create_study(storage=sqlite_db, study_name=study_name, \n                                sampler=TPESampler(n_startup_trials=35, multivariate=True, seed=0),\n                                direction=\"maximize\", load_if_exists=True)\n\n    study.optimize(objective, n_trials=100)\n    print(f\"Best optimized roc-auc: {study.best_value:0.5f}\")\n    print(f\"Best hyperparameters: {study.best_params}\")\n    catboost_params = study.best_params\nelse:\n    catboost_params = {\n        'loss_function': 'Logloss',\n        'eval_metric': 'AUC',\n        'learning_rate': 0.08114394459649094,\n        'iterations': 1000,\n        'depth': 6,\n        'random_strength': 0,\n        'l2_leaf_reg': 0.7047064221215757,\n        'task_type': 'GPU',\n        'random_seed': 50,\n        'verbose': False    \n    }","metadata":{"execution":{"iopub.status.busy":"2024-10-22T01:49:36.933911Z","iopub.execute_input":"2024-10-22T01:49:36.934480Z","iopub.status.idle":"2024-10-22T01:49:37.139574Z","shell.execute_reply.started":"2024-10-22T01:49:36.934416Z","shell.execute_reply":"2024-10-22T01:49:37.138330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove 'task_type' if it's already in catboost_params to avoid duplication\ncatboost_params.pop('task_type', None)\n\ncv = StratifiedKFold(5, shuffle=True, random_state=0)\ncv_splits = cv.split(train, y)\nscores = []\ntest_preds = []\n\ntrain_test_pool = Pool(test, cat_features=train.columns.values)\n\n# Cross-validation loop\nfor i, (train_idx, val_idx) in enumerate(cv_splits):\n    train_train_fold, train_val_fold = train.loc[train_idx], train.loc[val_idx]\n    y_train_fold, y_val_fold = y.loc[train_idx], y.loc[val_idx]\n    \n    # Create Pool objects for training and validation\n    train_train_pool = Pool(train_train_fold, y_train_fold, cat_features=train.columns.values)\n    train_valid_pool = Pool(train_val_fold, y_val_fold, cat_features=train.columns.values)\n    \n    # Initialize the CatBoostClassifier with the parameters, enforcing 'CPU' task type\n    model = CatBoostClassifier(**catboost_params, task_type='CPU')\n    \n    # Fit the model with early stopping\n    model.fit(train_train_pool, eval_set=train_valid_pool, verbose=False, early_stopping_rounds=200)\n    \n    # Predict probabilities and calculate ROC AUC score\n    val_pred = model.predict_proba(train_valid_pool)[:, 1]\n    score = roc_auc_score(y_val_fold, val_pred)\n    \n    # Store validation scores and test set predictions\n    scores.append(score)\n    test_pred = model.predict_proba(train_test_pool)[:, 1]\n    test_preds.append(test_pred)\n    \n    print(f'Fold {i + 1} roc_auc_score: {score:.3f}')\n\nprint(f'Cross-validated roc_auc_score: {np.mean(scores):.3f} +/- {np.std(scores):.3f}')\nprint(f'Max roc_auc_score score: {np.max(scores):.3f}')\nprint(f'Min roc_auc_score score: {np.min(scores):.3f}')","metadata":{"execution":{"iopub.status.busy":"2024-10-22T01:49:37.140984Z","iopub.execute_input":"2024-10-22T01:49:37.141415Z","iopub.status.idle":"2024-10-22T01:58:56.307726Z","shell.execute_reply.started":"2024-10-22T01:49:37.141344Z","shell.execute_reply":"2024-10-22T01:58:56.306288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('../input/playground-series-s4e10/sample_submission.csv')\nsubmission['loan_status'] = np.mean(test_preds, axis=0)\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-22T01:59:07.612313Z","iopub.execute_input":"2024-10-22T01:59:07.613267Z","iopub.status.idle":"2024-10-22T01:59:07.786031Z","shell.execute_reply.started":"2024-10-22T01:59:07.613210Z","shell.execute_reply":"2024-10-22T01:59:07.784599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"another try","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, RandomizedSearchCV, GridSearchCV, RepeatedStratifiedKFold, cross_val_score, cross_val_predict, RepeatedKFold\nfrom sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier, StackingClassifier\nfrom sklearn.metrics import roc_auc_score","metadata":{"execution":{"iopub.status.busy":"2024-10-24T04:39:58.263922Z","iopub.execute_input":"2024-10-24T04:39:58.264404Z","iopub.status.idle":"2024-10-24T04:39:58.271556Z","shell.execute_reply.started":"2024-10-24T04:39:58.264361Z","shell.execute_reply":"2024-10-24T04:39:58.270076Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"obj_cols = (['person_home_ownership', 'loan_intent', 'loan_grade',\n            'cb_person_default_on_file'])\nnum_cols = (['person_age', 'person_income', 'person_emp_length',\n            'loan_amnt', 'loan_int_rate', 'loan_percent_income', \n            'cb_person_cred_hist_length'])\n\ndef preprocess_data(df, obj_cols, train=False):\n    \n    for col in obj_cols:\n        df[col] = df[col].astype('category')\n    \n    df['person_age'] = df['person_age'].astype('int32')#0~4,294,967,295\n    df['cb_person_cred_hist_length'] = df['cb_person_cred_hist_length'].astype('int32') \n    df['person_age'] = df['person_age'].clip(None, 80)  #below 80\n    df['person_emp_length'] = df['person_emp_length'].clip(None, 65) #below 65\n    \n    if train:\n\n        df['loan_status'] = df['loan_status'].astype('int8')#0~255  0と1しかない時はint8\n        \n    return df\n        \ntrain = preprocess_data(train, obj_cols ,train=True)\ntest = preprocess_data(test, obj_cols)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T04:40:04.543374Z","iopub.execute_input":"2024-10-24T04:40:04.544713Z","iopub.status.idle":"2024-10-24T04:40:04.565931Z","shell.execute_reply.started":"2024-10-24T04:40:04.544656Z","shell.execute_reply":"2024-10-24T04:40:04.564647Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"RandomForestClassifier model","metadata":{}},{"cell_type":"code","source":"X = train.drop(columns=['loan_status'], axis=1)\nY = train['loan_status']\n\nskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=1)\n\ntrain_dummies = pd.get_dummies(X[obj_cols], drop_first=True, dtype='int8')\ntest_dummies = pd.get_dummies(test[obj_cols], drop_first=True, dtype='int8')\n\ntrain_dummies, test_dummies = train_dummies.align(test_dummies, join='left', axis=1, fill_value=0)\n\nRF_train = pd.concat([X.drop(columns=obj_cols, axis=1), train_dummies], axis=1)\nRF_test = pd.concat([test.drop(columns=obj_cols, axis=1), test_dummies], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T04:40:07.423219Z","iopub.execute_input":"2024-10-24T04:40:07.423656Z","iopub.status.idle":"2024-10-24T04:40:07.471237Z","shell.execute_reply.started":"2024-10-24T04:40:07.423615Z","shell.execute_reply":"2024-10-24T04:40:07.469691Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"%%time\n\n# random research\nparam_dist = {\n    'n_estimators': [100, 150],\n    'max_depth': [10, 15],\n    'min_samples_split': [2, 5],\n    'min_samples_leaf': [1, 2]\n}\n\nrandom_search = RandomizedSearchCV(RandomForestClassifier(n_jobs=-1), param_dist, n_iter=50, cv=5, scoring='roc_auc', n_jobs=-1, random_state=1)\nrandom_search.fit(RF_train, Y)\n\nprint(\"Best parameters: \", random_search.best_params_)\n\nbest_rf_md = random_search.best_estimator_\n\nscores, rf_oof_preds, rf_test_preds = [], [], []\n\nfor i, (train_index, test_index) in enumerate(skf.split(RF_train, Y)):\n    print(f\"Fold {i} \")\n    \n    X_train, X_test = RF_train.iloc[train_index], RF_train.iloc[test_index]\n    y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]\n    \n    preds = best_rf_md.predict_proba(X_test)[:, 1]\n    \n    oof_preds = pd.DataFrame({'y': y_test.values, 'rf_preds': preds, 'fold': i})\n    rf_oof_preds.append(oof_preds)\n    \n    score = roc_auc_score(y_test, preds)\n    print(f\"The oof ROC-AUC score is {score}\")\n    scores.append(score)\n    \n    test_preds = pd.DataFrame({'rf_preds': best_rf_md.predict_proba(RF_test)[:, 1], 'fold': i})\n    rf_test_preds.append(test_preds)\n\nrf_oof_score = np.mean(scores)\nrf_std = np.std(scores)\nprint(f\"The average oof ROC-AUC score of the RandomForest model is {rf_oof_score}\")\nprint(f\"The std oof ROC-AUC score of the RandomForest model is {rf_std}\")\n\nimportances = best_rf_md.feature_importances_\nfeatures = RF_train.columns\nimportant_features = pd.Series(importances, index=features).sort_values(ascending=False)\nprint(important_features.head(10))  \n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T04:33:30.986679Z","iopub.execute_input":"2024-10-21T04:33:30.987236Z","iopub.status.idle":"2024-10-21T04:42:57.159587Z","shell.execute_reply.started":"2024-10-21T04:33:30.987192Z","shell.execute_reply":"2024-10-21T04:42:57.158409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LightGBM model","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom lightgbm import LGBMClassifier\n\n# ランダムサーチで連続的なパラメータ範囲を設定する\nlgb_param_dist = {\n    'learning_rate': np.linspace(0.09, 0.1, 100),  # 0.01から0.1までの連続値を100個生成\n    'n_estimators': np.arange(50, 201, 10),        # 50から150まで10刻みで探索\n    'max_depth': np.arange(10, 21, 1),              # 5から15までの整数値を探索\n    'reg_alpha': np.random.uniform(0, 0.5, 100),   # 0から0.5までの連続値をランダムに100個生成\n    'reg_lambda': np.random.uniform(0, 0.5, 100),  # 同上\n    'num_leaves': np.arange(20, 41, 1),            # 20から40までの整数値を探索\n    'colsample_bytree': np.linspace(0.3, 0.7, 100) # 0.3から0.7までの連続値を100個生成\n}\n\n# ランダムサーチの実行 (n_iter=50にして、より多くの組み合わせを探索)\nrandom_search = RandomizedSearchCV(\n    LGBMClassifier(n_jobs=-1, verbose=-1),\n    lgb_param_dist,\n    n_iter=50,  # 50回の異なる組み合わせをランダムに試す\n    scoring='roc_auc',\n    cv=3,\n    n_jobs=-1,\n    random_state=42\n)\n\n# モデルの学習\nrandom_search.fit(X, Y)\n\n# 最適なパラメータの表示\nprint(\"Best parameters found: \", random_search.best_params_)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T04:53:52.666130Z","iopub.execute_input":"2024-10-24T04:53:52.666590Z","iopub.status.idle":"2024-10-24T04:56:22.995462Z","shell.execute_reply.started":"2024-10-24T04:53:52.666546Z","shell.execute_reply":"2024-10-24T04:56:22.994009Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Best parameters found:  {'reg_lambda': 0.4024415902150582, 'reg_alpha': 0.3457054016562055, 'num_leaves': 21, 'n_estimators': 180, 'max_depth': 13, 'learning_rate': 0.09898989898989899, 'colsample_bytree': 0.5343434343434343}\n","output_type":"stream"}]},{"cell_type":"code","source":"from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n\nX = train.drop(columns=['loan_status'], axis=1)\nY = train['loan_status']\n\nbest_lgb_params = {\n    'learning_rate': 0.09898989898989899,\n    'n_estimators': 180,\n    'max_depth': 13,\n    'reg_alpha': 0.3457054016562055,\n    'reg_lambda': 0.4024415902150582,\n    'num_leaves': 21,\n    'colsample_bytree': 0.5,\n    'verbose': -1,\n    'n_jobs': -1\n}\n\nscores, lgb_oof_preds, lgb_test_preds = list(), list(), list()\n\nfor i, (train_index, test_index) in enumerate(skf.split(X, Y)):\n    print(f\" Fold {i} \")\n    \n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = Y[train_index], Y.iloc[test_index]\n    \n    lgb_md = LGBMClassifier(**best_lgb_params)\n    \n    lgb_md.fit(\n        X_train, y_train,\n        eval_set=[(X_test, y_test)],  \n        eval_metric='auc',            \n        callbacks=[early_stopping(10), log_evaluation(0)]  \n    )\n\n    preds = lgb_md.predict_proba(X_test)[:, 1]\n    \n    oof_preds = pd.DataFrame()\n    oof_preds['y'] = y_test.values\n    oof_preds['lgb_preds'] = preds\n    oof_preds['fold'] = i\n    lgb_oof_preds.append(oof_preds)\n    \n    score = roc_auc_score(y_test, preds)\n    print(f\"The oof ROC-AUC score is {score}\")\n    scores.append(score)\n    \n    test_preds = pd.DataFrame()\n    test_preds['lgb_preds'] = lgb_md.predict_proba(test)[:, 1]\n    test_preds['fold'] = i\n    lgb_test_preds.append(test_preds)\n\nlgb_oof_score = np.mean(scores)\nlgb_std = np.std(scores)\nprint(f\"The average oof ROC-AUC score of the LGBM model is {lgb_oof_score}\")\nprint(f\"The std oof ROC-AUC score of the LGBM model is {lgb_std}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T04:58:40.004770Z","iopub.execute_input":"2024-10-24T04:58:40.005270Z","iopub.status.idle":"2024-10-24T04:58:50.898245Z","shell.execute_reply.started":"2024-10-24T04:58:40.005224Z","shell.execute_reply":"2024-10-24T04:58:50.897088Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":" Fold 0 \nTraining until validation scores don't improve for 10 rounds\nEarly stopping, best iteration is:\n[110]\tvalid_0's auc: 0.95714\tvalid_0's binary_logloss: 0.146933\nThe oof ROC-AUC score is 0.9571397021048864\n Fold 1 \nTraining until validation scores don't improve for 10 rounds\nEarly stopping, best iteration is:\n[155]\tvalid_0's auc: 0.955991\tvalid_0's binary_logloss: 0.148183\nThe oof ROC-AUC score is 0.9559909706385022\n Fold 2 \nTraining until validation scores don't improve for 10 rounds\nDid not meet early stopping. Best iteration is:\n[180]\tvalid_0's auc: 0.958587\tvalid_0's binary_logloss: 0.143322\nThe oof ROC-AUC score is 0.9585867930110549\n Fold 3 \nTraining until validation scores don't improve for 10 rounds\nDid not meet early stopping. Best iteration is:\n[177]\tvalid_0's auc: 0.957352\tvalid_0's binary_logloss: 0.151542\nThe oof ROC-AUC score is 0.9573515063520438\n Fold 4 \nTraining until validation scores don't improve for 10 rounds\nDid not meet early stopping. Best iteration is:\n[177]\tvalid_0's auc: 0.955806\tvalid_0's binary_logloss: 0.155126\nThe oof ROC-AUC score is 0.9558061330366407\nThe average oof ROC-AUC score of the LGBM model is 0.9569750210286256\nThe std oof ROC-AUC score of the LGBM model is 0.0010100816092851127\n","output_type":"stream"}]},{"cell_type":"markdown","source":"CatBoost","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom catboost import CatBoostClassifier\nX = train.drop(columns=['loan_status'], axis=1)\nY = train['loan_status']\n\ncat_features = X.select_dtypes(include=['category']).columns.tolist()\n\n\n# CatBoost用の連続的なパラメータ範囲設定\ncat_param_dist = {\n    'learning_rate': np.linspace(0.09, 0.1, 100),    # 0.01から0.1の範囲で100個の値を探索\n    'depth': np.arange(8, 16, 1),                    # 4から10までの整数値を探索\n    'l2_leaf_reg': np.random.uniform(0, 5, 100),     # 1から9の範囲で連続的に探索\n    'iterations': np.arange(100, 201, 50),           # 100から300まで50刻み\n    'border_count': np.arange(32, 129, 32),          # 32, 64, 96, 128といった範囲を探索\n    'random_strength': np.random.uniform(1, 3, 100)  # 1から3の範囲でランダムに探索\n}\n\n# ランダムサーチの実行\nrandom_search = RandomizedSearchCV(\n    estimator=CatBoostClassifier(verbose=0),  \n    param_distributions=cat_param_dist,\n    n_iter=50,  # より多くの組み合わせを試す\n    scoring='roc_auc',\n    cv=3,\n    random_state=42,\n    n_jobs=-1\n)\n\n# カテゴリ変数のリストを指定して学習\nrandom_search.fit(X, Y, cat_features=cat_features)\n\n# 最適なパラメータを表示\nprint(\"Best parameters: \", random_search.best_params_)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T05:34:04.949616Z","iopub.execute_input":"2024-10-24T05:34:04.950175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Best parameters from RandomizedSearchCV\nbest_cat_params = {\n    'random_strength': 1.781134720536659,\n    'learning_rate': 0.07818181818181819,\n    'l2_leaf_reg': 2.3636726248162034,\n    'iterations': 300,\n    'depth': 5,\n    'border_count': 96,\n    'verbose': 0,  # 学習時の詳細を出力しない\n}\n\n# 交差検証用のスコア保存リスト\nscores, cat_oof_preds, cat_test_preds = list(), list(), list()\n\n# 交差検証の実行\nfor i, (train_index, test_index) in enumerate(skf.split(X, Y)):\n    print(f\"Fold {i} \")\n    \n    # 訓練データとテストデータに分割\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = Y[train_index], Y.iloc[test_index]\n    \n    # CatBoostモデルに最適なパラメータを設定してインスタンス化\n    cat_md = CatBoostClassifier(**best_cat_params)\n    \n    # モデルの学習\n    cat_md.fit(\n        X_train, y_train,\n        eval_set=[(X_test, y_test)],  \n        cat_features=cat_features,  # カテゴリ変数のリスト\n        early_stopping_rounds=10,   # 早期終了の設定\n        use_best_model=True         # 最良のモデルを保存\n    )\n    \n    # テストデータに対する予測\n    preds = cat_md.predict_proba(X_test)[:, 1]\n    \n    # 予測結果を保存\n    oof_preds = pd.DataFrame()\n    oof_preds['y'] = y_test.values\n    oof_preds['cat_preds'] = preds\n    oof_preds['fold'] = i\n    cat_oof_preds.append(oof_preds)\n    \n    # ROC-AUCスコアの計算\n    score = roc_auc_score(y_test, preds)\n    print(f\"The oof ROC-AUC score is {score}\")\n    scores.append(score)\n    \n    # テストデータでの予測結果も保存\n    test_preds = pd.DataFrame()\n    test_preds['cat_preds'] = cat_md.predict_proba(test)[:, 1]\n    test_preds['fold'] = i\n    cat_test_preds.append(test_preds)\n\n# 交差検証の平均スコアと標準偏差の計算\ncat_oof_score = np.mean(scores)\ncat_std = np.std(scores)\nprint(f\"The 10-fold average oof ROC-AUC score of the CatBoost model is {cat_oof_score}\")\nprint(f\"The 10-fold std oof ROC-AUC score of the CatBoost model is {cat_std}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T05:30:16.199102Z","iopub.execute_input":"2024-10-24T05:30:16.199592Z","iopub.status.idle":"2024-10-24T05:31:10.978767Z","shell.execute_reply.started":"2024-10-24T05:30:16.199548Z","shell.execute_reply":"2024-10-24T05:31:10.977404Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Fold 0 \nThe oof ROC-AUC score is 0.9509657690285996\nFold 1 \nThe oof ROC-AUC score is 0.9491100114117128\nFold 2 \nThe oof ROC-AUC score is 0.9479355634094174\nFold 3 \nThe oof ROC-AUC score is 0.9478491272748271\nFold 4 \nThe oof ROC-AUC score is 0.9422702462655959\nThe 10-fold average oof ROC-AUC score of the CatBoost model is 0.9476261434780306\nThe 10-fold std oof ROC-AUC score of the CatBoost model is 0.0029046879446977883\n","output_type":"stream"}]},{"cell_type":"code","source":"X = train.drop(columns=['loan_status'], axis=1)\nY = train['loan_status']\n\ncat_features = X.select_dtypes(include=['category']).columns.tolist()\n\ncat_param_dist = {\n    'learning_rate': [0.01, 0.05, 0.1],\n    'depth': [4, 6, 8, 10],             \n    'l2_leaf_reg': [1, 3, 5, 7, 9],     \n    'iterations': [100, 200, 300],      \n    'border_count': [32, 64, 128],      \n    'random_strength': [1, 2, 3]       \n}\n\nrandom_search = RandomizedSearchCV(\n    estimator=CatBoostClassifier(verbose=0),  \n    param_distributions=cat_param_dist,\n    n_iter=15,\n    scoring='roc_auc',\n    cv=3,\n    random_state=42,\n    n_jobs=-1\n)\n\nrandom_search.fit(X, Y, cat_features=cat_features)\n\nprint(\"Best parameters: \", random_search.best_params_)\n\nbest_cat_params = random_search.best_params_\nscores, cat_oof_preds, cat_test_preds = list(), list(), list()\n\nfor i, (train_index, test_index) in enumerate(skf.split(X, Y)):\n    print(f\"Fold {i} \")\n    \n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = Y[train_index], Y.iloc[test_index]\n    \n    cat_md = CatBoostClassifier(**best_cat_params, verbose=0)\n    cat_md.fit(X_train, y_train, eval_set=[(X_test, y_test)], cat_features=cat_features, early_stopping_rounds=10, use_best_model=True)\n    \n    preds = cat_md.predict_proba(X_test)[:, 1]\n    \n    oof_preds = pd.DataFrame()\n    oof_preds['y'] = y_test.values\n    oof_preds['cat_preds'] = preds\n    oof_preds['fold'] = i\n    cat_oof_preds.append(oof_preds)\n    \n    score = roc_auc_score(y_test, preds)\n    print(f\"The oof ROC-AUC score is {score}\")\n    scores.append(score)\n    \n    test_preds = pd.DataFrame()\n    test_preds['cat_preds'] = cat_md.predict_proba(test)[:, 1]\n    test_preds['fold'] = i\n    cat_test_preds.append(test_preds)\n\ncat_oof_score = np.mean(scores)\ncat_std = np.std(scores)\nprint(f\"The 10-fold average oof ROC-AUC score of the CatBoost model is {cat_oof_score}\")\nprint(f\"The 10-fold std oof ROC-AUC score of the CatBoost model is {cat_std}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T06:02:10.529759Z","iopub.execute_input":"2024-10-21T06:02:10.530717Z","iopub.status.idle":"2024-10-21T06:08:38.983973Z","shell.execute_reply.started":"2024-10-21T06:02:10.530671Z","shell.execute_reply":"2024-10-21T06:08:38.982880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 目的変数と特徴量の分割\nX = train.drop(columns=['loan_status'], axis=1)\nY = train['loan_status']\n\n# カテゴリ変数の指定\ncat_features = X.select_dtypes(include=['category']).columns.tolist()\n\n# CatBoostのパラメータ範囲を設定\ncat_param_dist = {\n    'learning_rate': [0.01, 0.05, 0.1],\n    'depth': [4, 6, 8, 10],             # ツリーの深さ\n    'l2_leaf_reg': [1, 3, 5, 7, 9],     # L2正則化項\n    'iterations': [100, 200, 300],      # イテレーション回数\n    'border_count': [32, 64, 128],      # binの数\n    'random_strength': [1, 2, 3]        # ランダム性の強さ\n}\n\n# 10-foldのStratifiedKFoldの設定\nskf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n\n# ランダムサーチの実行 (n_iterを15に減少、cv=3に減少)\nrandom_search = RandomizedSearchCV(\n    estimator=CatBoostClassifier(verbose=0),  # verbose=0 でログ出力を抑える\n    param_distributions=cat_param_dist,\n    n_iter=15,\n    scoring='roc_auc',\n    cv=3,\n    random_state=42,\n    n_jobs=-1\n)\n\n# カテゴリ変数を指定して学習\nrandom_search.fit(X, Y, cat_features=cat_features)\n\n# 最適なパラメータを表示\nprint(\"Best parameters found: \", random_search.best_params_)\n\n# 最適なパラメータでCatBoostモデルを再学習\nbest_cat_params = random_search.best_params_\nscores, cat_oof_preds, cat_test_preds = list(), list(), list()\n\nfor i, (train_index, test_index) in enumerate(skf.split(X, Y)):\n    print(f\"------------ Working on Fold {i} ------------\")\n    \n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = Y[train_index], Y.iloc[test_index]\n    \n    # CatBoostClassifierモデルで再学習\n    cat_md = CatBoostClassifier(**best_cat_params, verbose=0)\n    cat_md.fit(X_train, y_train, eval_set=[(X_test, y_test)], cat_features=cat_features, early_stopping_rounds=10, use_best_model=True)\n    \n    preds = cat_md.predict_proba(X_test)[:, 1]\n    \n    oof_preds = pd.DataFrame()\n    oof_preds['y'] = y_test.values\n    oof_preds['cat_preds'] = preds\n    oof_preds['fold'] = i\n    cat_oof_preds.append(oof_preds)\n    \n    score = roc_auc_score(y_test, preds)\n    print(f\"The oof ROC-AUC score is {score}\")\n    scores.append(score)\n    \n    test_preds = pd.DataFrame()\n    test_preds['cat_preds'] = cat_md.predict_proba(test)[:, 1]\n    test_preds['fold'] = i\n    cat_test_preds.append(test_preds)\n\ncat_oof_score = np.mean(scores)\ncat_std = np.std(scores)\nprint(f\"The 10-fold average oof ROC-AUC score of the CatBoost model is {cat_oof_score}\")\nprint(f\"The 10-fold std oof ROC-AUC score of the CatBoost model is {cat_std}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-21T06:11:13.969472Z","iopub.execute_input":"2024-10-21T06:11:13.970271Z","iopub.status.idle":"2024-10-21T06:18:45.669070Z","shell.execute_reply.started":"2024-10-21T06:11:13.970226Z","shell.execute_reply":"2024-10-21T06:18:45.667972Z"},"trusted":true},"execution_count":null,"outputs":[]}]}